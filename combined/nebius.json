{
  "_defaults": {
    "message_roles": [
      "system",
      "user",
      "assistant"
    ],
    "parameters": [
      {
        "defaultValue": 256,
        "key": "max_tokens",
        "maxValue": 8192,
        "minValue": 1
      },
      {
        "defaultValue": 0.7,
        "key": "temperature",
        "maxValue": 2,
        "minValue": 0
      },
      {
        "defaultValue": 1,
        "key": "top_p",
        "maxValue": 1,
        "minValue": 0
      },
      {
        "defaultValue": null,
        "key": "stop",
        "skipValues": [
          null,
          []
        ],
        "type": "array-of-strings"
      },
      {
        "defaultValue": 1,
        "key": "n",
        "maxValue": 10,
        "minValue": 1
      },
      {
        "defaultValue": true,
        "key": "stream",
        "type": "boolean"
      },
      {
        "defaultValue": null,
        "key": "tool_choice",
        "options": [
          {
            "name": "None",
            "value": "none"
          },
          {
            "name": "Auto",
            "value": "auto"
          },
          {
            "name": "Required",
            "value": "required"
          },
          {
            "name": "Custom",
            "schema": {
              "type": "json"
            },
            "value": "custom"
          }
        ],
        "rule": {
          "default": {
            "condition": "tools",
            "else": null,
            "then": "auto"
          }
        },
        "skipValues": [
          null,
          []
        ],
        "type": "non-view-manage-data"
      }
    ],
    "pricing_formula": {
      "request": {
        "operands": [
          {
            "value": "input_tokens"
          },
          {
            "value": "rates.request_token"
          }
        ],
        "operation": "multiply"
      },
      "response": {
        "operands": [
          {
            "value": "output_tokens"
          },
          {
            "value": "rates.response_token"
          }
        ],
        "operation": "multiply"
      }
    }
  },
  "id": "nebius",
  "models": {
    "NousResearch/Hermes-3-Llama-405B": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 131072,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "NousResearch/Hermes-3-Llama-405B",
      "max_output_tokens": 131072,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "NousResearch/Hermes-4-405B": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 131072,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "NousResearch/Hermes-4-405B",
      "max_output_tokens": 131072,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "NousResearch/Hermes-4-70B": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 131072,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "NousResearch/Hermes-4-70B",
      "max_output_tokens": 131072,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "Qwen/QwQ-32B": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 131072,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "Qwen/QwQ-32B",
      "max_output_tokens": 131072,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "Qwen/QwQ-32B-fast": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 131072,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "Qwen/QwQ-32B-fast",
      "max_output_tokens": 131072,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "Qwen/Qwen2-VL-72B-Instruct": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "features": {
        "vision": true
      },
      "id": "Qwen/Qwen2-VL-72B-Instruct",
      "max_output_tokens": 8192,
      "modality": {
        "input": [
          "text",
          "image"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "Qwen/Qwen2-VL-7B-Instruct": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "features": {
        "vision": true
      },
      "id": "Qwen/Qwen2-VL-7B-Instruct",
      "max_output_tokens": 4096,
      "modality": {
        "input": [
          "text",
          "image"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "Qwen/Qwen2.5-1.5B-Instruct": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "Qwen/Qwen2.5-1.5B-Instruct",
      "max_output_tokens": 4096,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "Qwen/Qwen2.5-32B-Instruct": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "Qwen/Qwen2.5-32B-Instruct",
      "max_output_tokens": 8192,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "Qwen/Qwen2.5-32B-Instruct-fast": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "Qwen/Qwen2.5-32B-Instruct-fast",
      "max_output_tokens": 8192,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "Qwen/Qwen2.5-72B-Instruct": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "Qwen/Qwen2.5-72B-Instruct",
      "max_output_tokens": 8192,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "Qwen/Qwen2.5-72B-Instruct-fast": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "Qwen/Qwen2.5-72B-Instruct-fast",
      "max_output_tokens": 8192,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "Qwen/Qwen2.5-Coder-32B-Instruct": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "Qwen/Qwen2.5-Coder-32B-Instruct",
      "max_output_tokens": 8192,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "Qwen/Qwen2.5-Coder-32B-Instruct-fast": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "Qwen/Qwen2.5-Coder-32B-Instruct-fast",
      "max_output_tokens": 8192,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "Qwen/Qwen2.5-Coder-7B": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "Qwen/Qwen2.5-Coder-7B",
      "max_output_tokens": 4096,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "Qwen/Qwen2.5-Coder-7B-Instruct": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "Qwen/Qwen2.5-Coder-7B-Instruct",
      "max_output_tokens": 4096,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "Qwen/Qwen2.5-Coder-7B-Instruct-fast": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "Qwen/Qwen2.5-Coder-7B-Instruct-fast",
      "max_output_tokens": 4096,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "Qwen/Qwen2.5-Coder-7B-fast": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "Qwen/Qwen2.5-Coder-7B-fast",
      "max_output_tokens": 4096,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "Qwen/Qwen2.5-VL-72B-Instruct": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32000,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "features": {
        "vision": true
      },
      "id": "Qwen/Qwen2.5-VL-72B-Instruct",
      "max_output_tokens": 32000,
      "modality": {
        "input": [
          "text",
          "image"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "Qwen/Qwen3-14B": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 40960,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "Qwen/Qwen3-14B",
      "max_output_tokens": 40960,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "Qwen/Qwen3-235B-A22B-Instruct-2507": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 262144,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "max_output_tokens": 262144,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 262144,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "max_output_tokens": 262144,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "Qwen/Qwen3-30B-A3B": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 40960,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "Qwen/Qwen3-30B-A3B",
      "max_output_tokens": 40960,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "Qwen/Qwen3-30B-A3B-Instruct-2507": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 262144,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "max_output_tokens": 262144,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "Qwen/Qwen3-30B-A3B-Thinking-2507": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 262144,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "max_output_tokens": 262144,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "Qwen/Qwen3-32B": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 40960,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "Qwen/Qwen3-32B",
      "max_output_tokens": 40960,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "Qwen/Qwen3-32B-fast": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 40960,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "Qwen/Qwen3-32B-fast",
      "max_output_tokens": 40960,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "Qwen/Qwen3-Coder-30B-A3B-Instruct": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 262144,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "max_output_tokens": 262144,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "Qwen/Qwen3-Coder-480B-A35B-Instruct": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 262144,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "max_output_tokens": 262144,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "aaditya/Llama3-OpenBioLLM-70B": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "aaditya/Llama3-OpenBioLLM-70B",
      "max_output_tokens": 8192,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "aaditya/Llama3-OpenBioLLM-8B": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "aaditya/Llama3-OpenBioLLM-8B",
      "max_output_tokens": 4096,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "allenai/OLMo-7B-Instruct-hf": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "allenai/OLMo-7B-Instruct-hf",
      "max_output_tokens": 4096,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "cognitivecomputations/dolphin-2.9.2-mixtral-8x22b": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "cognitivecomputations/dolphin-2.9.2-mixtral-8x22b",
      "max_output_tokens": 32768,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct",
      "max_output_tokens": 4096,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct-fast": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct-fast",
      "max_output_tokens": 4096,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "deepseek-ai/DeepSeek-R1-0528": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 163840,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "deepseek-ai/DeepSeek-R1-0528",
      "max_output_tokens": 163840,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "pricing": {
        "currency": "USD",
        "tokens": {
          "input": 0.8,
          "output": 2.4,
          "unit": "USD_per_million_tokens"
        },
        "type": "pay_as_you_go"
      },
      "type": "chat"
    },
    "deepseek-ai/DeepSeek-R1-0528-fast": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "deepseek-ai/DeepSeek-R1-0528-fast",
      "max_output_tokens": 32768,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "deepseek-ai/DeepSeek-V3": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 163840,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "deepseek-ai/DeepSeek-V3",
      "max_output_tokens": 163840,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "deepseek-ai/DeepSeek-V3-0324": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 163840,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "deepseek-ai/DeepSeek-V3-0324",
      "max_output_tokens": 163840,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "deepseek-ai/DeepSeek-V3-0324-fast": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "deepseek-ai/DeepSeek-V3-0324-fast",
      "max_output_tokens": 32768,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "google/gemma-2-27b-it": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "google/gemma-2-27b-it",
      "max_output_tokens": 8192,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "google/gemma-2-27b-it-fast": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "google/gemma-2-27b-it-fast",
      "max_output_tokens": 8192,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "google/gemma-2-2b-it": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "google/gemma-2-2b-it",
      "max_output_tokens": 4096,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "google/gemma-2-2b-it-fast": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "google/gemma-2-2b-it-fast",
      "max_output_tokens": 4096,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "google/gemma-2-9b-it": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "google/gemma-2-9b-it",
      "max_output_tokens": 4096,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "google/gemma-2-9b-it-fast": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "google/gemma-2-9b-it-fast",
      "max_output_tokens": 4096,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "google/gemma-3-27b-it": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 110000,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "features": {
        "vision": true
      },
      "id": "google/gemma-3-27b-it",
      "max_output_tokens": 110000,
      "modality": {
        "input": [
          "text",
          "image"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "google/gemma-3-27b-it-fast": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 110000,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "features": {
        "vision": true
      },
      "id": "google/gemma-3-27b-it-fast",
      "max_output_tokens": 110000,
      "modality": {
        "input": [
          "text",
          "image"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "llava-hf/llava-1.5-13b-hf": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "features": {
        "vision": true
      },
      "id": "llava-hf/llava-1.5-13b-hf",
      "max_output_tokens": 4096,
      "modality": {
        "input": [
          "text",
          "image"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "llava-hf/llava-1.5-7b-hf": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "features": {
        "vision": true
      },
      "id": "llava-hf/llava-1.5-7b-hf",
      "max_output_tokens": 4096,
      "modality": {
        "input": [
          "text",
          "image"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "meta-llama/Llama-3.2-1B-Instruct": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "meta-llama/Llama-3.2-1B-Instruct",
      "max_output_tokens": 4096,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "meta-llama/Llama-3.2-3B-Instruct": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "meta-llama/Llama-3.2-3B-Instruct",
      "max_output_tokens": 4096,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "meta-llama/Llama-3.3-70B-Instruct": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "meta-llama/Llama-3.3-70B-Instruct",
      "max_output_tokens": 8192,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "meta-llama/Llama-3.3-70B-Instruct-fast": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "meta-llama/Llama-3.3-70B-Instruct-fast",
      "max_output_tokens": 8192,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "meta-llama/Llama-Guard-3-8B": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "meta-llama/Llama-Guard-3-8B",
      "max_output_tokens": 4096,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "meta-llama/Meta-Llama-3.1-405B-Instruct": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "meta-llama/Meta-Llama-3.1-405B-Instruct",
      "max_output_tokens": 8192,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "meta-llama/Meta-Llama-3.1-70B-Instruct": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "meta-llama/Meta-Llama-3.1-70B-Instruct",
      "max_output_tokens": 8192,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "meta-llama/Meta-Llama-3.1-70B-Instruct-fast": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "meta-llama/Meta-Llama-3.1-70B-Instruct-fast",
      "max_output_tokens": 8192,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "meta-llama/Meta-Llama-3.1-8B-Instruct": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "max_output_tokens": 4096,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "meta-llama/Meta-Llama-3.1-8B-Instruct-fast": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "meta-llama/Meta-Llama-3.1-8B-Instruct-fast",
      "max_output_tokens": 4096,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "microsoft/Phi-3-medium-128k-instruct": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 128000,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "microsoft/Phi-3-medium-128k-instruct",
      "max_output_tokens": 128000,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "microsoft/Phi-3-medium-128k-instruct-fast": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 128000,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "microsoft/Phi-3-medium-128k-instruct-fast",
      "max_output_tokens": 128000,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "microsoft/Phi-3-mini-4k-instruct": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "microsoft/Phi-3-mini-4k-instruct",
      "max_output_tokens": 4096,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "microsoft/Phi-3-mini-4k-instruct-fast": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "microsoft/Phi-3-mini-4k-instruct-fast",
      "max_output_tokens": 4096,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "microsoft/Phi-3.5-MoE-instruct": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "microsoft/Phi-3.5-MoE-instruct",
      "max_output_tokens": 4096,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "microsoft/Phi-3.5-mini-instruct": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "microsoft/Phi-3.5-mini-instruct",
      "max_output_tokens": 4096,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "mistralai/Devstral-Small-2505": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 128000,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "mistralai/Devstral-Small-2505",
      "max_output_tokens": 128000,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "mistralai/Mistral-Nemo-Instruct-2407": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "mistralai/Mistral-Nemo-Instruct-2407",
      "max_output_tokens": 8192,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "mistralai/Mistral-Nemo-Instruct-2407-fast": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "mistralai/Mistral-Nemo-Instruct-2407-fast",
      "max_output_tokens": 8192,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "mistralai/Mixtral-8x22B-Instruct-v0.1": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "mistralai/Mixtral-8x22B-Instruct-v0.1",
      "max_output_tokens": 32768,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "mistralai/Mixtral-8x22B-Instruct-v0.1-fast": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "mistralai/Mixtral-8x22B-Instruct-v0.1-fast",
      "max_output_tokens": 32768,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "mistralai/Mixtral-8x7B-Instruct-v0.1": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "features": {
        "function_calling": true
      },
      "id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
      "max_output_tokens": 32768,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "mistralai/Mixtral-8x7B-Instruct-v0.1-fast": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "features": {
        "function_calling": true
      },
      "id": "mistralai/Mixtral-8x7B-Instruct-v0.1-fast",
      "max_output_tokens": 32768,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "moonshotai/Kimi-K2-Instruct": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 131072,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "moonshotai/Kimi-K2-Instruct",
      "max_output_tokens": 131072,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF",
      "max_output_tokens": 8192,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF-fast": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF-fast",
      "max_output_tokens": 8192,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "nvidia/Llama-3_1-Nemotron-Ultra-253B-v1": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 131072,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "nvidia/Llama-3_1-Nemotron-Ultra-253B-v1",
      "max_output_tokens": 131072,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "openai/gpt-oss-120b": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 131072,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "openai/gpt-oss-120b",
      "max_output_tokens": 131072,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "openai/gpt-oss-20b": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 131072,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "openai/gpt-oss-20b",
      "max_output_tokens": 131072,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "zai-org/GLM-4.5": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 131072,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "zai-org/GLM-4.5",
      "max_output_tokens": 131072,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    },
    "zai-org/GLM-4.5-Air": {
      "_parameters": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 131072,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "id": "zai-org/GLM-4.5-Air",
      "max_output_tokens": 131072,
      "modality": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "type": "chat"
    }
  },
  "name": "nebius",
  "schema_version": "2.0"
}
